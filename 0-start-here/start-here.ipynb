{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DepthAI - Start Here\n",
    "\n",
    "This notebook will read and display frames from the rgb camera."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these modules are for DepthAI\n",
    "import blobconverter\n",
    "import cv2\n",
    "import depthai\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these matplotlib modules will enable us to display the image in the Jupyter notebook\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# these modules will enable us to build a simple event driven UI in the Jupyter notebook\n",
    "import ipywidgets as widgets\n",
    "import threading\n",
    "from IPython.display import display, Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline that tells DepthAI what operations to perform while running.\n",
    "pipeline = depthai.Pipeline()\n",
    "assert pipeline is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add the color camera node to the pipeline.\n",
    "colorCamera = pipeline.createColorCamera()\n",
    "assert colorCamera is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the preview size to 300x300.  \n",
    "# This frame will be available as the 'preview' output of the node.\n",
    "colorCamera.setPreviewSize(300, 300)  \n",
    "colorCamera.setInterleaved(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# XLinkOut is a \"way out\" from the device. Any data you want to transfer to host need to be send via XLink.\n",
    "xoutRgb = pipeline.createXLinkOut()\n",
    "assert xoutRgb is not None\n",
    "\n",
    "# For the rgb camera output, we want the XLink stream to be named \"rgb\"\n",
    "xoutRgb.setStreamName(\"rgb\")\n",
    "\n",
    "# Linking camera preview to XLink input, so that the frames will be sent to host\n",
    "colorCamera.preview.link(xoutRgb.input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Pipeline is now fully constructed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a function to be called in the thread that will be created in the next notebook cell.\n",
    "def showVideo(button):\n",
    "    \n",
    "    # ask the device to run the pipeline.\n",
    "    with depthai.Device(pipeline) as device:\n",
    "\n",
    "        # From this point, the Device will be in \"running\" mode and will start sending data via XLink.\n",
    "        queueRgb = device.getOutputQueue(\"rgb\")\n",
    "\n",
    "        # Frame will be an image from \"rgb\" stream.\n",
    "        frame = None    \n",
    "\n",
    "        # Main host-side application loop\n",
    "        while True:\n",
    "            \n",
    "            # we try to fetch the data from nn/rgb queues. \n",
    "            # tryGet() will return either the data packet or None if there isn't any.\n",
    "            inRgb = queueRgb.tryGet()\n",
    "\n",
    "            if inRgb is not None:\n",
    "                # If the packet from RGB camera is present, \n",
    "                # we're retrieving the frame in OpenCV format using getCvFrame().\n",
    "                frame = inRgb.getCvFrame()\n",
    "\n",
    "            if frame is not None:\n",
    "                \n",
    "                # adjust the frame size for conversion and display in the notebook.\n",
    "                rows, columns, _ = frame.shape\n",
    "                resizedFrame = cv2.resize(frame, (int(columns/2), int(rows/2)))\n",
    "                resizedFrame = cv2.flip(resizedFrame, 1)\n",
    "                \n",
    "                # convert the frame from a OpenCV numpy array to a jpeg \n",
    "                # so that we can display it in the Jupyter notebook.\n",
    "                _, jpg = cv2.imencode('.jpeg', resizedFrame)\n",
    "                \n",
    "                # show the frame on the screen.\n",
    "                display_handle.update(Image(data=jpg.tobytes()))\n",
    "                if stopButton.value==True:\n",
    "                    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the button widget\n",
    "stopButton = widgets.ToggleButton(\n",
    "    value=False,\n",
    "    description='Stop',\n",
    "    disabled=False,\n",
    "    button_style='danger',\n",
    "    tooltip='Stop the Video',\n",
    "    icon='square'\n",
    ")\n",
    "\n",
    "# initialize the display window\n",
    "display_handle=display(None, display_id=True)\n",
    "# display the stop button\n",
    "display(stopButton)\n",
    "# create a thread that calls the showVideo() function above\n",
    "thread = threading.Thread(target=showVideo, args=(stopButton,))\n",
    "thread.start()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
